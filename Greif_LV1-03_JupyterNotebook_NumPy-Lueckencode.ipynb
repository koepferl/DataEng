{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction - eine Methode der \"Dimensionality Reduction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nur Überschriften und Erklärungen im Notebook sind auf Deutsch, ``#comments`` und ``code`` sind auf Englisch. Dieses Mindestmaß an Englisch hat sich als gute Praxis erwiesen. Es ist ratsam sich das Coding in Englisch anzugewöhnen (oder beizubehalten), da Sie so auch den ``code`` ohne Weiteres an internationale Partner weitergeben können oder in Foren wie https://github.com gemeinsam Projekte bearbeiten können.\n",
    "\n",
    "# Inhalt\n",
    "* 1 Setup\n",
    "* 2 PCA mit NumPy\n",
    "* 3 PCA mit scikit-learn\n",
    "* 4 Anhänge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 | Setup\n",
    "\n",
    "Hier werden wichtige Module ``modules`` geladen und es wird überprüft, dass die nötigen Mindestanforderungen für die Softwareaktualität gegeben sind.\n",
    "\n",
    "* ``Python 3.5`` oder neuer\n",
    "* es könnte evtl. mit ``Python 2.x`` laufen, aber davon wird abgeraten\n",
    "* Scikit-Learn ≥0.20 (PCA https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"dim_reduction\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird eine plotting routine definiert, da es in Python sehr umständlich ist schöne Vektoren zu plotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CI color\n",
    "lila = mpl.cm.get_cmap('plasma')\n",
    "\n",
    "def plot_PCs(data, fig, ax, svd=None, pca=None):\n",
    "\n",
    "        \n",
    "    ax.plot(X[:, 0], X[:, 1], 'o', color=lila(0.8), label=r'Daten $\\mu=0$')\n",
    "    \n",
    "    if svd is not None:\n",
    "        PC1 = svd[:,0]\n",
    "        PC2 = svd[:,1]\n",
    "        \n",
    "        # line \n",
    "        ax.plot([-10 * PC1[0], 10 * PC1[0]], [-10 * PC1[1], 10 * PC1[1]], 'k-', zorder=1)\n",
    "        ax.plot([-10 * PC2[0], 10 * PC2[0]], [-10 * PC2[1], 10 * PC2[1]], 'k:', zorder=1)\n",
    "        \n",
    "        # principal components from SVD\n",
    "        ax.arrow(0, 0, PC1[0], PC1[1], head_width=0.3, linewidth=2, length_includes_head=True, head_length=0.3, fc=lila(0.3), ec=lila(0.3))\n",
    "        ax.arrow(0, 0, PC2[0], PC2[1], head_width=0.3, linewidth=2, length_includes_head=True, head_length=0.3, fc='w', ec=lila(0.3))\n",
    "        plt.text(1.5,-1, 'NumPy SVD', color=lila(0.3))\n",
    "    \n",
    "    if pca is not None:\n",
    "        # principal components from scikit-learn\n",
    "        ax.arrow(0, 0, pca.components_[0,0], pca.components_[0,1], head_width=0.3, linewidth=2, length_includes_head=True, head_length=0.3, fc=lila(0.1), ec=lila(0.1))\n",
    "        ax.arrow(0, 0, pca.components_[1,0], pca.components_[1,1], head_width=0.3, linewidth=2, length_includes_head=True, head_length=0.3, fc='w', ec=lila(0.1))\n",
    "        plt.text(1.5,1, 'scikit-learn PCA', color=lila(0.1))\n",
    "    \n",
    "    \n",
    "    # axis\n",
    "    ax.plot([0], [0], 'ko')\n",
    "    ax.arrow(-10, 0, 20, 0, head_width=0.5, linewidth=1, length_includes_head=True, \n",
    "             head_length=0.5, fc='k', ec='k', alpha=0.7)\n",
    "    ax.arrow(0, -10, 0, 20, head_width=0.5, linewidth=1, length_includes_head=True, \n",
    "             head_length=0.5, fc='k', ec='k', alpha=0.7)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.set_xlabel(r'X$_{m,1}-\\mu_{m,1}$')\n",
    "    ax.set_ylabel(r'X$_{m,2}-\\mu_{m,2}$')\n",
    "\n",
    "    \n",
    "    ax.set_xlim(-10, 10)\n",
    "    ax.set_ylim(-10, 10)\n",
    "    ax.grid(True, zorder=0)\n",
    "\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 | PCA mit NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun, da wir uns mit der Theorie vertraut gemacht haben, können wir beginnen. \n",
    "Zuerst führen wir die PCA mit NumPy durch. Diese Variante ist umständlicher, aber man sieht mehr, was hinter den Kulissen vorgeht.\n",
    "\n",
    "Wir geben unsere Matrix als ``np.array`` ein. Hier sei Matrix $A=$``X``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[3, 7], [-4, -6], [7, 8], [1, -1], [-4, -1], [-3, -7]])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir schauen uns kurz die Datenpunkte an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using plotting command from above\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.add_subplot(121)\n",
    "ax = plot_PCs(data=X, fig=fig, ax=ax)#, svd=Vt.T[:, :2], pca=pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass die Daten bereits zentriert sind. Das erkennt man auch an der Matrix ``X`` (Spaltensummen = 0). Das überprüfen wir auch nochmal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir führen die SVD mit NumPy durch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for general use do not forget to center\n",
    "X_centered = X - X.mean(axis=0)\n",
    "\n",
    "# Singular Value Decomposition\n",
    "U, s, Vt = np.linalg.svd(X_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ob die Faktorisierung auch funktioniert hat, wird hier getestet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X.shape\n",
    "\n",
    "S = np.zeros(X_centered.shape)\n",
    "S[:n, :n] = np.diag(s)\n",
    "\n",
    "# test X == USV^T?\n",
    "np.allclose(X_centered, U.dot(S).dot(Vt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigentlich interessiert uns nur ``Vt``. Das ist die Matrix mit den Eigenvektoren von $A^TA$.\n",
    "\n",
    "Wir erhalten unsere Matrix $W_{n\\times 2}$ für $d=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_2comp = Vt.T[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_2comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Principal Components können auch ausgegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1 = Vt.T[:, 0]\n",
    "PC2 = Vt.T[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir zeichnen nun die mit NumPy gefundenen PC1 und PC2 ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.add_subplot(121)\n",
    "ax = plot_PCs(data=X, fig=fig, ax=ax, svd=Vt.T[:, :2])#, pca=pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten die Matrix $A_E(m\\times d)$ indem wir das Matrixprodukt $A_{m\\times n}W_{n\\times d}$ ausführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2D_using_svd = X_centered.dot(W_2comp)\n",
    "X2D_using_svd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 | scikit-learn PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun schauen wir uns PCA mit ``sklearn`` etwas genauer an. Die Matrix $A$ sei hier ``X``. Zentriert wird bei ``sklearn`` automatisch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 2, svd_solver='full')#, random_state=42)\n",
    "X2D_using_scikit = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_E from scikit-learn\n",
    "X2D_using_scikit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun der Vergleich mit dem Ergebnis von NumPy (siehe Abschnitt 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_E from NumPy\n",
    "X2D_using_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Zahlenwerte sind gleich, aber die Vorzeichen sind anders. Wie kommt das?\n",
    "\n",
    "Schauen wir uns dazu nochmal die PC1 und PC2 an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PC1, PC2 with sklearn\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PC1, PC2 with NumPy\n",
    "Vt.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es Vektoren gleicher Basis, allerdings mit negativen Vorfaktoren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.add_subplot(121)\n",
    "ax = plot_PCs(data=X, fig=fig, ax=ax, svd=Vt.T[:, :2], pca=pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit ``sklearn`` kann man sich praktischerweise auch die Varianzen ausgeben lassen. Fast 95% liegen bei diesem Beispiel in PC1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun zurück zum den Folien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 | Anhänge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier finden Sie andere Darstellungen des gleichen Problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure setup\n",
    "fig = plt.figure(figsize=(18,5))\n",
    "\n",
    "# subplot 1 (only data and PC1)\n",
    "ax = fig.add_subplot(131)\n",
    "ax = plot_PCs(data=X, fig=fig, ax=ax)#, svd=Vt.T[:, :2], pca=pca)\n",
    "ax.plot([-10 * PC1[0], 10 * PC1[0]], [-10 * PC1[1], 10 * PC1[1]], 'k-', zorder=1)\n",
    "\n",
    "# subplot 2 (data, PC1, PC2)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2 = plot_PCs(data=X, fig=fig, ax=ax2, svd=Vt.T[:, :2], pca=pca)\n",
    "\n",
    "# subplot 3 (zoomin of subplot 2)\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3 = plot_PCs(data=X, fig=fig, ax=ax3, svd=Vt.T[:, :2], pca=pca)\n",
    "ax3.set_xlim(-5, 5)\n",
    "ax3.set_ylim(-5, 5)\n",
    "save_fig('BV_SVD_PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the feature-extracted dataset A_E = A W\n",
    "plt.plot(X2D_using_svd[:,0], X2D_using_svd[:,1], 'o', color=lila(0.3))\n",
    "plt.arrow(0, 0, 1, 0, head_width=0.5, linewidth=2, length_includes_head=True, head_length=0.5, fc=lila(0.3), ec=lila(0.3))\n",
    "plt.arrow(0, 0, 0, -1, head_width=0.5, linewidth=2, length_includes_head=True, head_length=0.5, fc='w', ec=lila(0.3))\n",
    "plt.xlim(-10, 10)\n",
    "plt.ylim(-10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
